{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413e3c9-57ce-412a-818b-5db0ea112d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 使用CPU设备\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 数据路径配置\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"Crescent\")\n",
    "image_dir = data_dir\n",
    "annotation_file = os.path.join(current_dir, \"Crescentlabel.xlsx\")\n",
    "\n",
    "# 读取并预处理标注数据\n",
    "def load_and_preprocess_annotations(annotation_file):\n",
    "    annotations = pd.read_excel(annotation_file)\n",
    "    \n",
    "    # 自动检测标签列\n",
    "    label_col = None\n",
    "    possible_label_names = ['LABLE', 'LABEL', 'Label', 'label', '分级', '评分', 'fibrosis']\n",
    "    for name in possible_label_names:\n",
    "        if name in annotations.columns:\n",
    "            label_col = name\n",
    "            break\n",
    "    if label_col is None:\n",
    "        raise ValueError(\"无法找到标签列\")\n",
    "    \n",
    "    annotations.rename(columns={label_col: 'LABEL'}, inplace=True)\n",
    "    \n",
    "    # 标准化ID格式\n",
    "    annotations['ID'] = annotations['ID'].apply(lambda x: str(x).zfill(2))\n",
    "    \n",
    "    # 如果标签不是0/1，调整为0/1\n",
    "    if annotations['LABEL'].max() > 1:\n",
    "        annotations['LABEL'] = annotations['LABEL'] - 1\n",
    "    \n",
    "    # 检查类别平衡\n",
    "    class_counts = annotations['LABEL'].value_counts()\n",
    "    print(f\"\\n类别分布:\\n{class_counts}\")\n",
    "    print(f\"正负类比例: {class_counts[1]/class_counts[0]:.2f}:1\")\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "annotations = load_and_preprocess_annotations(annotation_file)\n",
    "\n",
    "# 自定义数据集类（增强错误处理）\n",
    "class CrescentDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe.copy()\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.valid_samples = []\n",
    "        \n",
    "        # 预先检查所有图像可用性\n",
    "        for idx, row in self.dataframe.iterrows():\n",
    "            img_path = os.path.join(self.image_dir, f\"{row['ID']}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                self.valid_samples.append((img_path, row['LABEL']))\n",
    "            else:\n",
    "                print(f\"警告：跳过不存在的图像 {img_path}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.valid_samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"加载图像 {img_path} 出错: {str(e)}\")\n",
    "            # 返回空白图像和-1标签（训练时会过滤掉）\n",
    "            return torch.zeros(3, 224, 224), torch.tensor(-1, dtype=torch.long)\n",
    "\n",
    "# 数据增强配置（适合医学图像）\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 轻量级模型定义（适合CPU）\n",
    "class CrescentModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CrescentModel, self).__init__()\n",
    "        # 使用预训练的resnet18（更轻量）\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # 冻结前几层（减少计算量）\n",
    "        for param in list(self.backbone.parameters())[:50]:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # 修改最后一层\n",
    "        num_ftrs = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# 训练和验证函数（减少重复代码）\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, running_correct = 0.0, 0\n",
    "    all_probs, all_labels = [], []\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        # 过滤掉无效样本（标签为-1的）\n",
    "        valid_mask = labels != -1\n",
    "        if not valid_mask.any():\n",
    "            continue\n",
    "            \n",
    "        inputs = inputs[valid_mask].to(device)\n",
    "        labels = labels[valid_mask].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "        # 计算概率（用于AUC）\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_correct.double() / len(loader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, running_correct = 0.0, 0\n",
    "    all_probs, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            # 过滤无效样本\n",
    "            valid_mask = labels != -1\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "                \n",
    "            inputs = inputs[valid_mask].to(device)\n",
    "            labels = labels[valid_mask].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # 计算概率（用于AUC）\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_correct.double() / len(loader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "# 早停类\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 验证集性能不再提升的等待epoch数\n",
    "            delta (float): 被视为有提升的最小变化量\n",
    "            verbose (bool): 如果为True，打印早停信息\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_acc_max = -np.inf\n",
    "\n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        '''Saves model when validation accuracy increases.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "        self.val_acc_max = val_acc\n",
    "\n",
    "# 主训练流程\n",
    "def main():\n",
    "    # 超参数配置（适合CPU）\n",
    "    batch_size = 16  # 较小的batch size适合CPU内存\n",
    "    num_epochs = 15  # 减少epoch数加快训练\n",
    "    num_workers = 0  # CPU环境下设为0\n",
    "    \n",
    "    # 5折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    X = annotations\n",
    "    y = annotations['LABEL']\n",
    "    \n",
    "    # 保存所有fold的结果\n",
    "    all_train_labels = []\n",
    "    all_train_probs = []\n",
    "    all_val_labels = []\n",
    "    all_val_probs = []\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n========== Fold {fold + 1}/5 ==========\")\n",
    "        \n",
    "        # 准备数据\n",
    "        train_df = X.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = X.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        train_dataset = CrescentDataset(train_df, image_dir, data_transforms['train'])\n",
    "        val_dataset = CrescentDataset(val_df, image_dir, data_transforms['val'])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=num_workers)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=num_workers)\n",
    "        \n",
    "        # 初始化模型（每折重新开始）\n",
    "        model = CrescentModel(num_classes=2).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)\n",
    "        \n",
    "        # 初始化早停\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "        \n",
    "        # 训练记录\n",
    "        best_acc = 0.0\n",
    "        history = {'train_loss': [], 'val_loss': [], \n",
    "                  'train_acc': [], 'val_acc': [],\n",
    "                  'train_auc': [], 'val_auc': []}\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            \n",
    "            # 训练\n",
    "            train_loss, train_acc, train_probs, train_labels = train_epoch(\n",
    "                model, train_loader, criterion, optimizer, device)\n",
    "            train_auc = roc_auc_score(train_labels, train_probs)\n",
    "            \n",
    "            # 验证\n",
    "            val_loss, val_acc, val_probs, val_labels = validate_epoch(\n",
    "                model, val_loader, criterion, device)\n",
    "            val_auc = roc_auc_score(val_labels, val_probs)\n",
    "            \n",
    "            # 学习率调整\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # 记录历史\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc.item())\n",
    "            history['val_acc'].append(val_acc.item())\n",
    "            history['train_auc'].append(train_auc)\n",
    "            history['val_auc'].append(val_auc)\n",
    "            \n",
    "            # 打印训练和验证指标\n",
    "            print(f'Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | AUC: {train_auc:.4f}')\n",
    "            print(f'Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | AUC: {val_auc:.4f}')\n",
    "            \n",
    "            # 早停检查\n",
    "            early_stopping(val_acc, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "            \n",
    "            # 保存最佳模型\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'best_model_fold{fold}.pth')\n",
    "                # 保存训练集和验证集的预测结果\n",
    "                np.savez(f'fold{fold}_predictions.npz',\n",
    "                        train_probs=train_probs, train_labels=train_labels,\n",
    "                        val_probs=val_probs, val_labels=val_labels)\n",
    "        \n",
    "        # 加载最佳模型\n",
    "        model.load_state_dict(torch.load(f'best_model_fold{fold}.pth'))\n",
    "        \n",
    "        # 获取最佳模型在训练集和验证集上的预测\n",
    "        _, _, train_probs, train_labels = validate_epoch(\n",
    "            model, train_loader, criterion, device)\n",
    "        val_loss, val_acc, val_probs, val_labels = validate_epoch(\n",
    "            model, val_loader, criterion, device)\n",
    "        val_auc = roc_auc_score(val_labels, val_probs)\n",
    "        print(f'Final Validation - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | AUC: {val_auc:.4f}')\n",
    "        \n",
    "        # 保存本折结果\n",
    "        all_train_labels.extend(train_labels)\n",
    "        all_train_probs.extend(train_probs)\n",
    "        all_val_labels.extend(val_labels)\n",
    "        all_val_probs.extend(val_probs)\n",
    "        \n",
    "        # 计算本折指标\n",
    "        fold_metrics.append({\n",
    "            'fold': fold + 1,\n",
    "            'train_acc': accuracy_score(train_labels, train_probs > 0.5),\n",
    "            'train_auc': roc_auc_score(train_labels, train_probs),\n",
    "            'val_acc': accuracy_score(val_labels, val_probs > 0.5),\n",
    "            'val_auc': val_auc,\n",
    "            'val_f1': f1_score(val_labels, val_probs > 0.5)\n",
    "        })\n",
    "        \n",
    "        # 绘制训练曲线\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Val Loss')\n",
    "        plt.legend(); plt.title(f'Fold {fold+1} Loss')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history['train_acc'], label='Train Acc')\n",
    "        plt.plot(history['val_acc'], label='Val Acc')\n",
    "        plt.legend(); plt.title(f'Fold {fold+1} Accuracy')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history['train_auc'], label='Train AUC')\n",
    "        plt.plot(history['val_auc'], label='Val AUC')\n",
    "        plt.legend(); plt.title(f'Fold {fold+1} ROC-AUC')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'training_curve_fold{fold}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 整体评估\n",
    "    # 整体评估\n",
    "    y_train_true = np.array(all_train_labels)\n",
    "    y_train_probs = np.array(all_train_probs)\n",
    "    y_val_true = np.array(all_val_labels)\n",
    "    y_val_probs = np.array(all_val_probs)\n",
    "    \n",
    "    # 1. 计算各项指标\n",
    "    y_train_pred = y_train_probs > 0.5\n",
    "    y_val_pred = y_val_probs > 0.5\n",
    "\n",
    "    # 训练集指标\n",
    "    train_metrics = {\n",
    "        'accuracy': accuracy_score(y_train_true, y_train_pred),\n",
    "        'precision': precision_score(y_train_true, y_train_pred),\n",
    "        'recall': recall_score(y_train_true, y_train_pred),\n",
    "        'f1': f1_score(y_train_true, y_train_pred),\n",
    "        'roc_auc': roc_auc_score(y_train_true, y_train_probs),\n",
    "        'pr_auc': average_precision_score(y_train_true, y_train_probs),\n",
    "    }\n",
    "\n",
    "    # 验证集指标\n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val_true, y_val_pred),\n",
    "        'precision': precision_score(y_val_true, y_val_pred),\n",
    "        'recall': recall_score(y_val_true, y_val_pred),\n",
    "        'f1': f1_score(y_val_true, y_val_pred),\n",
    "        'roc_auc': roc_auc_score(y_val_true, y_val_probs),\n",
    "        'pr_auc': average_precision_score(y_val_true, y_val_probs),\n",
    "        'kappa': cohen_kappa_score(y_val_true, y_val_pred)\n",
    "    }\n",
    "\n",
    "    # 2. 打印结果\n",
    "    print(\"\\n================ Final 5-Fold CV Results ================\")\n",
    "    print(\"\\n=== Training Set ===\")\n",
    "    print(f\"Accuracy:    {train_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision:   {train_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:      {train_metrics['recall']:.4f}\")\n",
    "    print(f\"F1-score:    {train_metrics['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC:     {train_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR-AUC:      {train_metrics['pr_auc']:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Validation Set ===\")\n",
    "    print(f\"Accuracy:    {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision:   {val_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:      {val_metrics['recall']:.4f}\")\n",
    "    print(f\"F1-score:    {val_metrics['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC:     {val_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR-AUC:      {val_metrics['pr_auc']:.4f}\")\n",
    "    print(f\"Cohen's κ:   {val_metrics['kappa']:.4f}\")\n",
    "\n",
    "    # 3. 绘制混淆矩阵\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(confusion_matrix(y_val_true, y_val_pred), \n",
    "                annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    # 4. 绘制ROC曲线（训练集和验证集在同一张图上）\n",
    "    train_fpr, train_tpr, _ = roc_curve(y_train_true, y_train_probs)\n",
    "    val_fpr, val_tpr, _ = roc_curve(y_val_true, y_val_probs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(train_fpr, train_tpr, label=f'Train ROC (AUC = {train_metrics[\"roc_auc\"]:.3f})', color='blue', linestyle='--')\n",
    "    plt.plot(val_fpr, val_tpr, label=f'Validation ROC (AUC = {val_metrics[\"roc_auc\"]:.3f})', color='red')  # 修改这里\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves (Train vs Validation)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig('roc_curve_combined.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. 保存所有fold的指标\n",
    "    fold_metrics_df = pd.DataFrame(fold_metrics)\n",
    "    fold_metrics_df.to_csv('fold_metrics.csv', index=False)\n",
    "    print(\"\\n各折详细指标已保存到 fold_metrics.csv\")\n",
    "    \n",
    "    print(\"\\n训练完成！所有结果和模型已保存。\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb7928-8803-4d80-b7dc-7de762936894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTHON 3.11",
   "language": "python",
   "name": "image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
