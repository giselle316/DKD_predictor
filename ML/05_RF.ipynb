{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305ec60-9589-4100-97ac-96c61f3113e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 训练模型\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, average_precision_score,\n",
    "                             roc_curve, precision_recall_curve, confusion_matrix,\n",
    "                             ConfusionMatrixDisplay, classification_report)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.drawing.image import Image\n",
    "from joblib import dump, load\n",
    "import shap\n",
    "\n",
    "# ====================== 配置参数 ======================\n",
    "CONFIG = {\n",
    "    'data_file': \"data.xlsx\",\n",
    "    'target': \"1yearegfr\",\n",
    "    'categorical_features': ['Crescent-shaped_changes', 'Interstitial_fibrosis'],\n",
    "    'numerical_features': ['ePWV', 'SII', '24h-UP', 'eGFR'],\n",
    "    'test_size': 0.25,\n",
    "    'random_state': 42,\n",
    "    'base_params': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 10,\n",
    "        'min_samples_leaf': 5,\n",
    "        'max_features': 0.1,\n",
    "        'class_weight': 'balanced',\n",
    "        'bootstrap': True,\n",
    "        'oob_score': False,\n",
    "        'random_state': 42,\n",
    "        'criterion': 'entropy',\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "    'param_grid': {\n",
    "        'n_estimators': [300, 500],\n",
    "        'max_depth': [3, 5, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 3, 5],\n",
    "        'max_features': ['sqrt', 0.1, 0.5]\n",
    "    },\n",
    "    'output_dir': \"results\\5_RF\"\n",
    "}\n",
    "\n",
    "# ====================== 工具函数 ======================\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"加载并预处理数据\"\"\"\n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "    print(\"数据前5行：\")\n",
    "    print(data.head())\n",
    "    print(\"\\n数据描述统计：\")\n",
    "    print(data.describe())\n",
    "    print(\"\\n缺失值检查：\")\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "def preprocess_features(data, categorical_features, numerical_features, target):\n",
    "    \"\"\"预处理特征数据\"\"\"\n",
    "    X = data[categorical_features + numerical_features].copy()\n",
    "    y = data[target]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_features:\n",
    "        X.loc[:, col] = label_encoder.fit_transform(X[col])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def find_optimal_threshold(y_true, y_prob, method='f1'):\n",
    "    \"\"\"自动寻找最佳分类阈值\"\"\"\n",
    "    if method == 'f1':\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "        return thresholds[np.argmax(f1_scores)]\n",
    "    \n",
    "    elif method == 'youden':\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "        return thresholds[np.argmax(tpr - fpr)]\n",
    "    \n",
    "    elif method == 'precision_recall':\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "        return thresholds[np.argmin(np.abs(precision - recall))]\n",
    "\n",
    "def evaluate_by_ckd_group(model, X, y_true, ckd_groups, threshold=0.5):\n",
    "    \"\"\"按CKD分组评估模型性能\"\"\"\n",
    "    group_metrics = {}\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    for group in sorted(ckd_groups.unique()):\n",
    "        group_indices = ckd_groups == group\n",
    "        if sum(group_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        group_y_true = y_true[group_indices]\n",
    "        group_y_prob = y_prob[group_indices]\n",
    "        group_y_pred = y_pred[group_indices]\n",
    "        \n",
    "        metrics = {\n",
    "            'n_samples': sum(group_indices),\n",
    "            'accuracy': accuracy_score(group_y_true, group_y_pred),\n",
    "            'precision': precision_score(group_y_true, group_y_pred, zero_division=0),\n",
    "            'recall': recall_score(group_y_true, group_y_pred, zero_division=0),\n",
    "            'f1': f1_score(group_y_true, group_y_pred, zero_division=0),\n",
    "            'roc_auc': roc_auc_score(group_y_true, group_y_prob) if len(np.unique(group_y_true)) > 1 else np.nan,\n",
    "            'pr_auc': average_precision_score(group_y_true, group_y_prob)\n",
    "        }\n",
    "        group_metrics[group] = metrics\n",
    "    \n",
    "    return group_metrics\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob, prefix=''):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    return {\n",
    "        f'{prefix}accuracy': accuracy_score(y_true, y_pred),\n",
    "        f'{prefix}precision': precision_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        f'{prefix}recall': recall_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        f'{prefix}f1': f1_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        f'{prefix}roc_auc': roc_auc_score(y_true, y_prob),\n",
    "        f'{prefix}pr_auc': average_precision_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "def save_individual_plots(best_rf, X_test, y_test, y_prob, X_train, y_train, y_train_prob, \n",
    "                         optimal_threshold_f1, optimal_threshold_youden, test_roc_auc, test_pr_auc):\n",
    "    \"\"\"保存各个子图\"\"\"\n",
    "    os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importance = pd.Series(best_rf.feature_importances_, index=X_train.columns)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    feature_importance.sort_values().plot(kind='barh')\n",
    "    plt.title('Feature Importance(Gini)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/01_feature_importance.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ROC曲线\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_prob)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_prob)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr_test, tpr_test, label=f'Test ROC (AUC = {test_roc_auc:.2f})')\n",
    "    plt.plot(fpr_train, tpr_train, label=f'Train ROC (AUC = {train_roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Train vs Test)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/02_roc_curve.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # PR曲线\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label=f'Test PR (AUC = {test_pr_auc:.2f})')\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "    opt_idx = np.argmax(f1_scores)\n",
    "    plt.scatter(recall[opt_idx], precision[opt_idx], color='red', label=f'Optimal F1 = {thresholds[opt_idx]:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/03_pr_curve.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 混淆矩阵\n",
    "    for threshold, suffix in zip([0.5, optimal_threshold_f1], ['default', 'optimal']):\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap='Blues' if suffix == 'default' else 'Greens', colorbar=False)\n",
    "        plt.title(f'Test CM ({suffix.capitalize()} Threshold={threshold:.2f})')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{CONFIG['output_dir']}/04_cm_{suffix}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # 阈值选择\n",
    "    thresholds_arr = np.linspace(0, 1, 100)\n",
    "    f1_scores_curve = [f1_score(y_test, (y_prob >= t).astype(int)) for t in thresholds_arr]\n",
    "    youden_j_curve = [recall_score(y_test, (y_prob >= t).astype(int)) - \n",
    "                     (1 - precision_score(y_test, (y_prob >= t).astype(int))) for t in thresholds_arr]\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(thresholds_arr, f1_scores_curve, label='F1 Score')\n",
    "    plt.plot(thresholds_arr, youden_j_curve, label=\"Youden's J\")\n",
    "    plt.axvline(optimal_threshold_f1, color='r', ls='--', label=f'Optimal F1 = {optimal_threshold_f1:.2f}')\n",
    "    plt.axvline(optimal_threshold_youden, color='g', ls='--', label=f'Optimal Youden = {optimal_threshold_youden:.2f}')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Threshold Selection')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/05_threshold_selection.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ====================== 主执行流程 ======================\n",
    "def main():\n",
    "    # 1. 数据准备\n",
    "    data = load_and_preprocess_data(CONFIG['data_file'])\n",
    "    X, y = preprocess_features(data, CONFIG['categorical_features'], \n",
    "                              CONFIG['numerical_features'], CONFIG['target'])\n",
    "    \n",
    "    # 2. 划分数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=CONFIG['test_size'], random_state=CONFIG['random_state'], stratify=y\n",
    "    )\n",
    "    \n",
    "    # 3. 交叉验证\n",
    "    rf = RandomForestClassifier(**CONFIG['base_params'])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=CONFIG['random_state'])\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    print(f\"\\n交叉验证结果（ROC AUC）：平均得分: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "    \n",
    "    # 4. 网格搜索\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(**{k: v for k, v in CONFIG['base_params'].items() \n",
    "                                          if k not in CONFIG['param_grid']}),\n",
    "        param_grid=CONFIG['param_grid'],\n",
    "        cv=5, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"\\n最佳参数: {grid_search.best_params_}\")\n",
    "    print(f\"最佳交叉验证ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # 5. 模型训练和预测\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    y_train_prob = best_rf.predict_proba(X_train)[:, 1]\n",
    "    y_prob = best_rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 6. 阈值优化\n",
    "    optimal_threshold_f1 = find_optimal_threshold(y_train, y_train_prob, 'f1')\n",
    "    y_pred_optimal = (y_prob >= optimal_threshold_f1).astype(int)\n",
    "    optimal_threshold_youden = find_optimal_threshold(y_train, y_train_prob, 'youden')\n",
    "    \n",
    "    # 7. 计算评估指标\n",
    "    test_roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    test_pr_auc = average_precision_score(y_test, y_prob)\n",
    "    \n",
    "    # 8. 可视化\n",
    "    save_individual_plots(best_rf, X_test, y_test, y_prob, X_train, y_train, \n",
    "                         y_train_prob, optimal_threshold_f1, optimal_threshold_youden, \n",
    "                         test_roc_auc, test_pr_auc)\n",
    "    \n",
    "    # 9. 保存模型和必要数据\n",
    "    os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "    dump(best_rf, f\"{CONFIG['output_dir']}/best_rf_model.joblib\")\n",
    "    dump(X_train, f\"{CONFIG['output_dir']}/X_train.joblib\")\n",
    "    dump(X_test, f\"{CONFIG['output_dir']}/X_test.joblib\")\n",
    "    dump(y_train, f\"{CONFIG['output_dir']}/y_train.joblib\")\n",
    "    dump(y_test, f\"{CONFIG['output_dir']}/y_test.joblib\")\n",
    "    dump(y_prob, f\"{CONFIG['output_dir']}/y_prob.joblib\")\n",
    "    \n",
    "    # 10. 汇总结果并导出 Excel\n",
    "    excel_path = os.path.join(CONFIG['output_dir'], \"RF_results.xlsx\")\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # 10.1 交叉验证结果\n",
    "        cv_df = pd.DataFrame({\n",
    "            \"fold\": np.arange(1, len(cv_scores)+1),\n",
    "            \"roc_auc\": cv_scores\n",
    "        })\n",
    "        cv_df.loc[\"mean\"] = [\"mean\", cv_scores.mean()]\n",
    "        cv_df.loc[\"std\"]  = [\"std\",  cv_scores.std()]\n",
    "        cv_df.to_excel(writer, sheet_name=\"CV_result\", index=False)\n",
    "\n",
    "        # 10.2 最佳参数\n",
    "        best_params_df = pd.Series(grid_search.best_params_).to_frame(\"value\")\n",
    "        best_params_df.to_excel(writer, sheet_name=\"Best_params\")\n",
    "\n",
    "        # 10.3 训练集和测试集性能\n",
    "        # 训练集性能\n",
    "        y_train_pred_default = (y_train_prob >= 0.5).astype(int)\n",
    "        train_metrics = pd.Series(\n",
    "            calculate_metrics(y_train, y_train_pred_default, y_train_prob, prefix=\"train_\")\n",
    "        ).to_frame(\"value\")\n",
    "        \n",
    "        # 测试集性能\n",
    "        y_test_pred_default = (y_prob >= 0.5).astype(int)\n",
    "        test_metrics = pd.Series(\n",
    "            calculate_metrics(y_test, y_test_pred_default, y_prob, prefix=\"test_\")\n",
    "        ).to_frame(\"value\")\n",
    "        \n",
    "        # 合并训练集和测试集性能\n",
    "        performance_df = pd.concat([train_metrics, test_metrics], axis=1)\n",
    "        performance_df.columns = ['train', 'test']\n",
    "        performance_df.to_excel(writer, sheet_name=\"Performance_metrics\")\n",
    "\n",
    "        # 10.4 按 CKD 分组评估\n",
    "        if \"CKD\" in data.columns:\n",
    "            ckd_groups = data.loc[X_test.index, \"CKD\"]\n",
    "            group_metrics = evaluate_by_ckd_group(best_rf, X_test, y_test,\n",
    "                                                  ckd_groups,\n",
    "                                                  threshold=0.5)\n",
    "            group_df = pd.DataFrame(group_metrics).T\n",
    "            group_df.index.name = \"CKD_stage\"\n",
    "            group_df.to_excel(writer, sheet_name=\"Metrics_by_CKD\")\n",
    "\n",
    "        # 10.5 特征重要性\n",
    "        feat_imp = pd.Series(best_rf.feature_importances_, index=X.columns)\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .to_frame(\"importance\")\n",
    "        feat_imp.to_excel(writer, sheet_name=\"Feature_importance\")\n",
    "\n",
    "    print(f\"\\n所有结果已汇总并保存至：{excel_path}\")\n",
    "    \n",
    "    print(\"\\n模型训练完成！模型和数据已保存，可以运行下一个cell进行SHAP分析。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e69f0-ccae-4ad7-894a-6df6d3eb36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: SHAP分析\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from joblib import dump, load\n",
    "import shap\n",
    "\n",
    "# ====================== 配置参数 ======================\n",
    "CONFIG = {\n",
    "    'output_dir': \"re0/5_RF\"\n",
    "}\n",
    "\n",
    "def _format_label(label: str) -> str:\n",
    "    \"\"\"统一格式化特征标签：下划线→空格；定量 2 位小数；定性整数\"\"\"\n",
    "    label = label.replace('_', ' ')\n",
    "    m = re.match(r'(.+?)\\s*=\\s*([\\d\\.eE\\-\\+]+)', label)\n",
    "    if not m:\n",
    "        return label\n",
    "    name, val_str = m.groups()\n",
    "    val = float(val_str)\n",
    "    # 若标签以 =0 或 =1 结尾，视为定性变量\n",
    "    if label.endswith(('=0', '=1')):\n",
    "        val_fmt = f'{int(round(val))}'\n",
    "    else:\n",
    "        val_fmt = f'{val:.2f}'.rstrip('0').rstrip('.')\n",
    "    return f'{name} = {val_fmt}'\n",
    "\n",
    "def _save_single_force(exp_single, save_path):\n",
    "    \"\"\"保存单张力图\"\"\"\n",
    "    fig = shap.plots.force(exp_single, matplotlib=True, show=False)\n",
    "    ax = fig.axes[0]\n",
    "\n",
    "    # 1. 收集并格式化文本\n",
    "    base_val = float(exp_single.base_values)\n",
    "    new_txts = []\n",
    "    for t in ax.texts:\n",
    "        txt = t.get_text().strip()\n",
    "        if txt.startswith('f(x)'):                    # 去掉 f(x)\n",
    "            continue\n",
    "        elif txt.startswith('base value'):            # 重写 base value\n",
    "            new_txts.append(('base', f'base value = {base_val:.2f}',\n",
    "                             t.get_position(), t.get_fontsize(),\n",
    "                             t.get_color(), t.get_horizontalalignment()))\n",
    "        else:                                         # 普通特征\n",
    "            new_txts.append(('feat', _format_label(txt),\n",
    "                             t.get_position(), t.get_fontsize(),\n",
    "                             t.get_color(), t.get_horizontalalignment()))\n",
    "\n",
    "    # 2. 删除旧文本\n",
    "    for t in list(ax.texts):\n",
    "        t.remove()\n",
    "\n",
    "    # 3. 重新添加\n",
    "    for typ, txt, pos, fs, col, ha in new_txts:\n",
    "        ax.text(*pos, txt, fontsize=fs, color=col, ha=ha, va='center')\n",
    "\n",
    "    # 4. 微调坐标轴\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels(['lower', 'higher'])\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.set_xticks([round(x_min, 2), round(x_max, 2)])\n",
    "    ax.set_xticklabels([f'{x_min:.2f}', f'{x_max:.2f}'])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def _save_shap_scatter_plots(exp, X_test, output_dir, max_features=20):\n",
    "    \"\"\"保存所有变量的SHAP值散点图\"\"\"\n",
    "    print(\"正在生成SHAP散点图...\")\n",
    "    \n",
    "    # 获取特征重要性排序\n",
    "    mean_abs_shap = np.abs(exp.values).mean(axis=0)\n",
    "    feature_importance_order = np.argsort(mean_abs_shap)[::-1]\n",
    "    \n",
    "    # 限制显示的特征数量\n",
    "    display_features = min(max_features, len(X_test.columns))\n",
    "    \n",
    "    for i in range(display_features):\n",
    "        feature_idx = feature_importance_order[i]\n",
    "        feature_name = X_test.columns[feature_idx]\n",
    "        \n",
    "        # 创建散点图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # 绘制SHAP值与特征值的散点图\n",
    "        plt.scatter(X_test.iloc[:, feature_idx], exp.values[:, feature_idx], \n",
    "                   alpha=0.6, s=20, c='steelblue', edgecolors='none')\n",
    "        \n",
    "        # 添加标签和标题\n",
    "        plt.xlabel(f'{feature_name} Value', fontsize=12)\n",
    "        plt.ylabel(f'SHAP Value for {feature_name}', fontsize=12)\n",
    "        plt.title(f'SHAP Dependence Plot: {feature_name}', fontsize=14)\n",
    "        \n",
    "        # 添加网格\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 保存图像\n",
    "        safe_feature_name = feature_name.replace('/', '_').replace('\\\\', '_').replace('*', '_')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/shap_scatter_{safe_feature_name}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    print(f\"已保存 {display_features} 个SHAP散点图\")\n",
    "\n",
    "def _save_shap_summary_plot(exp, output_dir, max_display=20):\n",
    "    \"\"\"保存SHAP摘要图（点图）\"\"\"\n",
    "    print(\"正在生成SHAP摘要图...\")\n",
    "    \n",
    "    # 创建摘要图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(exp.values, exp.data, feature_names=exp.feature_names, \n",
    "                     max_display=max_display, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/shap_summary_dot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 创建另一种颜色的摘要图（可选）\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(exp.values, exp.data, feature_names=exp.feature_names, \n",
    "                     max_display=max_display, show=False, color='coolwarm')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/shap_summary_dot_coolwarm.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"SHAP摘要图已保存\")\n",
    "\n",
    "def perform_shap_analysis():\n",
    "    \"\"\"执行SHAP分析\"\"\"\n",
    "    print(\"\\n开始 SHAP 分析...\")\n",
    "    \n",
    "    # 加载模型和数据\n",
    "    best_rf = load(f\"{CONFIG['output_dir']}/best_rf_model.joblib\")\n",
    "    X_test = load(f\"{CONFIG['output_dir']}/X_test.joblib\")\n",
    "    y_prob = load(f\"{CONFIG['output_dir']}/y_prob.joblib\")\n",
    "    \n",
    "    # 计算 SHAP 值\n",
    "    explainer = shap.TreeExplainer(best_rf)\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # 处理二分类情况\n",
    "    if len(shap_values.values.shape) == 3:\n",
    "        sv = shap_values.values[..., 1]\n",
    "        base = shap_values.base_values[..., 1]\n",
    "    else:\n",
    "        sv = shap_values.values\n",
    "        base = shap_values.base_values\n",
    "\n",
    "    feature_names = [c.replace('_', ' ') for c in X_test.columns]\n",
    "\n",
    "    exp = shap.Explanation(\n",
    "        values=sv,\n",
    "        base_values=base,\n",
    "        data=X_test.values,\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "\n",
    "    # 条形图\n",
    "    plt.figure()\n",
    "    shap.plots.bar(exp, max_display=20, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/shap_summary_bar.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 小提琴图\n",
    "    plt.figure()\n",
    "    shap.plots.violin(exp, max_display=20, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/shap_summary_violin.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 新增：SHAP摘要图（点图）\n",
    "    _save_shap_summary_plot(exp, CONFIG['output_dir'])\n",
    "    \n",
    "    # 新增：保存所有变量的SHAP值散点图\n",
    "    _save_shap_scatter_plots(exp, X_test, CONFIG['output_dir'])\n",
    "\n",
    "    # 力图（2 阴性 + 2 阳性）\n",
    "    # 阴性（概率最低 2 个）\n",
    "    neg_idx = y_prob.argsort()[:1]\n",
    "    for k, idx in enumerate(neg_idx, 1):\n",
    "        _save_single_force(exp[idx], f\"{CONFIG['output_dir']}/shap_force_neg{k}.png\")\n",
    "\n",
    "    # 阳性（概率最高 2 个）\n",
    "    pos_idx = y_prob.argsort()[-2:][::-1]\n",
    "    for k, idx in enumerate(pos_idx, 1):\n",
    "        _save_single_force(exp[idx], f\"{CONFIG['output_dir']}/shap_force_pos{k}.png\")\n",
    "    \n",
    "    # 将SHAP值添加到Excel文件中\n",
    "    try:\n",
    "        excel_path = os.path.join(CONFIG['output_dir'], \"RF_results.xlsx\")\n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            # 提取SHAP值 - 修复维度问题\n",
    "            if len(shap_values.values.shape) == 3:\n",
    "                # 对于二分类问题，选择第二类（索引1）的SHAP值\n",
    "                shap_array = shap_values.values[:, :, 1]\n",
    "            else:\n",
    "                shap_array = shap_values.values\n",
    "            \n",
    "            # 创建SHAP值DataFrame\n",
    "            shap_df = pd.DataFrame(shap_array, \n",
    "                                 index=X_test.index, \n",
    "                                 columns=[f\"SHAP_{col}\" for col in X_test.columns])\n",
    "            \n",
    "            # 添加预测概率和真实标签\n",
    "            y_test = load(f\"{CONFIG['output_dir']}/y_test.joblib\")\n",
    "            shap_df['predicted_probability'] = y_prob\n",
    "            shap_df['true_label'] = y_test.values\n",
    "            shap_df.to_excel(writer, sheet_name=\"SHAP_values\")\n",
    "\n",
    "            # SHAP特征重要性（均值绝对值）\n",
    "            if len(shap_values.values.shape) == 3:\n",
    "                mean_abs_shap = np.abs(shap_values.values[:, :, 1]).mean(axis=0)\n",
    "            else:\n",
    "                mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "            \n",
    "            shap_importance = pd.DataFrame({\n",
    "                'feature': X_test.columns,\n",
    "                'mean_abs_shap': mean_abs_shap\n",
    "            }).sort_values('mean_abs_shap', ascending=False)\n",
    "            shap_importance.to_excel(writer, sheet_name=\"SHAP_importance\", index=False)\n",
    "            \n",
    "        print(f\"\\nSHAP结果已添加到Excel文件：{excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"添加到Excel文件时出错：{e}\")\n",
    "    \n",
    "    print(\"\\nSHAP分析完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    perform_shap_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
